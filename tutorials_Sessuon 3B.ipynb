{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Detection and Description in Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a tutorial about feature detection and description in images. You will learn different features be derived from image. Our final goal is to use these features to do  traffic sign detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we will use some powerful packages for image processing including OpenCV and Scikit-image. \n",
    "More details about Opencv and Skimage please visit https://opencv-python-tutroals.readthedocs.io/en/latest/index.html and https://scikit-image.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature detection\n",
    "### 1.1 Point-based\n",
    "Harris corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "#img01_source = cv2.imread('./chessboard.jpg') # read an image, you can change it to your own picture\n",
    "img01_source = cv2.imread('./5.jpg') # 5.jpg   4.jpg\n",
    "img01_source_RGB = cv2.cvtColor(img01_source, cv2.COLOR_BGR2RGB) # Change BGR format to RGB format\n",
    "#Show\n",
    "plt.imshow(img01_source_RGB) # plt.imshow(img01_source,cmap=None)\n",
    "plt.title('img01_source_RGB')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "img01_gray = cv2.cvtColor (img01_source_RGB, cv2.COLOR_RGB2GRAY) # Convert RGB color image to gray scale image\n",
    "#Show\n",
    "plt.imshow(img01_gray,cmap=plt.cm.gray)\n",
    "plt.title('img01_gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "img01_gray = np.float32(img01_gray)\n",
    "dst = cv2.cornerHarris(img01_gray,2,3,0.04) # Harris corner\n",
    "dst = cv2.dilate(dst, (),dst,(-1,-1,),3) # result is dilated for marking the corners, not important\n",
    "#Show\n",
    "plt.imshow(dst,cmap=plt.cm.gray)\n",
    "plt.title('img01_Harris')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#Threshold for an optimal value, it may vary depending on the image\n",
    "img01_source_RGB[dst>0.01*dst.max()]=[255,0,0] # Parameters\n",
    "plt.show()\n",
    "plt.imshow(img01_source_RGB)\n",
    "plt.title('Point_harris')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Edge-based\n",
    "  1.2.1 Roberts, Prewitt, Sobel and Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import roberts, sobel, prewitt\n",
    "from skimage import color,io, feature\n",
    "\n",
    "img = io.imread('./11.jpg') # 11.jpg 99.jpg  31.jpg 10.jpg\n",
    "gray = color.rgb2gray(img)\n",
    "\n",
    "edge_roberts = roberts(gray)\n",
    "edge_sobel = sobel(gray)\n",
    "edge_prewitt = prewitt(gray)\n",
    "edge_canny=feature.canny(gray) # edge_canny=feature.canny(gray,sigma=3,low_threshold=None, high_threshold=None, mask=None, use_quantiles=False)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True,\n",
    "                       figsize=(20, 20))\n",
    "\n",
    "ax[0].imshow(edge_roberts, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Roberts Edge Detection')\n",
    "\n",
    "ax[1].imshow(edge_sobel, cmap=plt.cm.gray)\n",
    "ax[1].set_title('Sobel Edge Detection')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True,\n",
    "                       figsize=(20, 20))\n",
    "\n",
    "ax[0].imshow(edge_prewitt, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Prewitt Edge Detection')\n",
    "\n",
    "ax[1].imshow(edge_canny, cmap=plt.cm.gray)\n",
    "ax[1].set_title('Canny Edge Detection')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1.2.2 Hough detection: line and circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "### Hough line detection\n",
    "img_line = cv2.imread('./92.jpg') # 4.jpg\n",
    "gray1 = cv2.cvtColor(img_line,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray1,10,150,apertureSize = 3)\n",
    "\n",
    "lines = cv2.HoughLines(edges,1,np.pi/180,150)\n",
    "for line in lines:\n",
    "    for rho,theta in line:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 3000*(-b))\n",
    "        y1 = int(y0 + 3000*(a))\n",
    "        x2 = int(x0 - 3000*(-b))\n",
    "        y2 = int(y0 - 3000*(a))\n",
    "        cv2.line(img_line,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "#Show\n",
    "img_line = cv2.cvtColor(img_line,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_line,cmap=None)\n",
    "plt.title('Hough line')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "### Hough circle detection\n",
    "img_circle = cv2.imread('./1.jpg')\n",
    "img_circle_gray = cv2.cvtColor(img_circle,cv2.COLOR_BGR2GRAY)\n",
    "circles = cv2.HoughCircles(img_circle_gray,cv2.HOUGH_GRADIENT,1,20,\n",
    "                            param1=50,param2=30,minRadius=150,maxRadius=500)\n",
    "circles = np.uint16(np.around(circles))\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(img_circle,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(img_circle,(i[0],i[1]),2,(255,0,0),3) \n",
    "#Show\n",
    "cimg = cv2.cvtColor(img_circle,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(cimg,cmap=None)\n",
    "plt.title('Hough circle')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Region-based\n",
    "1.3.1 Threshold: Otsu's and Niblack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import  io, color\n",
    "from skimage.filters import (threshold_otsu, threshold_niblack)\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings # ignore warnings in python\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "### Read image and display\n",
    "img_source = io.imread('./2.jpg')\n",
    "gray = color.rgb2gray(img_source)\n",
    "#Show\n",
    "plt.imshow(img_source,cmap=None)\n",
    "plt.title('img_source')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### Otsu's\n",
    "thresh_otsu = threshold_otsu(gray)\n",
    "binary_otsu = gray < thresh_otsu\n",
    "#Show\n",
    "plt.imshow(binary_otsu, cmap=plt.cm.gray)\n",
    "plt.title('Otsu thresholding')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### Niblack\n",
    "thresh_niblack = threshold_niblack(gray, window_size =31, k =0.05)\n",
    "binary_niblack = gray < thresh_niblack\n",
    "#Show\n",
    "plt.imshow(binary_niblack, cmap=plt.cm.gray)\n",
    "plt.title('Niblack thresholding')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.2 Morphology: Erosion, dilation, opening and closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io,color,util\n",
    "from skimage.morphology import erosion, dilation, opening, closing, disk\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "img_source = io.imread('./5.jpg')\n",
    "gray = color.rgb2gray(img_source)\n",
    " #gray = util.invert(gray) # depending on the image let the foreground be white, and background be black\n",
    "plt.imshow(gray, cmap=plt.cm.gray)\n",
    "plt.title('Original image')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "selem = disk(6)\n",
    "erosion_img = erosion(gray, selem)\n",
    "dilated_img = dilation(gray, selem)\n",
    "opened_img = opening(gray, selem)\n",
    "closed_img = closing(gray, selem)\n",
    "\n",
    "#-----------------------Display images-----------------------#\n",
    "fig, ax = plt.subplots(ncols=4, sharex=True, sharey=True,\n",
    "                       figsize=(20, 20))\n",
    "\n",
    "ax[0].imshow(erosion_img, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Erosion operation')\n",
    "\n",
    "ax[1].imshow(dilated_img, cmap=plt.cm.gray)\n",
    "ax[1].set_title('Dilation operation')\n",
    "\n",
    "ax[2].imshow(opened_img, cmap=plt.cm.gray)\n",
    "ax[2].set_title('Opening operation')\n",
    "\n",
    "ax[3].imshow(closed_img, cmap=plt.cm.gray)\n",
    "ax[3].set_title('Closing operation')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Color feature\n",
    "Channel split and Color histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "img_source = cv2.imread('./2.jpg') # OpenCV by default reads images in BGR format\n",
    "img_source_RGB = cv2.cvtColor(img_source, cv2.COLOR_BGR2RGB) # this is our original image\n",
    "plt.imshow(img_source_RGB)\n",
    "plt.title('RGB format image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "### Split channel\n",
    "r,g,b = cv2.split(img_source_RGB) # or you can use the following commands\n",
    "# r = img5[:,:,0]\n",
    "# g = img5[:,:,1]\n",
    "# b = img5[:,:,2]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, sharex=True, sharey=True,\n",
    "                       figsize=(20, 20))\n",
    "\n",
    "ax[0].imshow(r, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Red Channel')\n",
    "\n",
    "ax[1].imshow(g, cmap=plt.cm.gray)\n",
    "ax[1].set_title('Green Channel')\n",
    "\n",
    "ax[2].imshow(b, cmap=plt.cm.gray)\n",
    "ax[2].set_title('Blue Channel')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### Color histgram\n",
    "color = ('b','g','r')  ### color RGB image has three channel: Red, Green and Blue. \n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([img_source],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Texture feature\n",
    "GLCM (Gray Level Co-occurrence Matrix), Gabor and LBP (Local Binary Pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from skimage.feature import local_binary_pattern\n",
    "import cv2\n",
    "\n",
    "img_source = cv2.imread('./5.jpg') # OpenCV by default reads images in BGR format\n",
    "img_source_RGB = cv2.cvtColor(img_source, cv2.COLOR_BGR2RGB) # this is our original image\n",
    "img_gray = cv2.cvtColor(img_source, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "# settings for LBP\n",
    "radius = 3\n",
    "n_points = 8 * radius\n",
    "lbp_default = local_binary_pattern(img_gray, n_points, radius,  method='default')\n",
    "lbp_ror = local_binary_pattern(img_gray, n_points, radius,  method='ror')\n",
    "lbp_uniform = local_binary_pattern(img_gray, n_points, radius,  method='uniform')\n",
    "lbp_var = local_binary_pattern(img_gray, n_points, radius,  method='var')\n",
    "\n",
    "#-----------------------------Display original images----------------------------------#\n",
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True,\n",
    "                       figsize=(20, 20))\n",
    "\n",
    "ax[0].imshow(img_source_RGB, cmap=None)\n",
    "ax[0].set_title('Origianl color image')\n",
    "\n",
    "ax[1].imshow(img_gray, cmap=plt.cm.gray)\n",
    "ax[1].set_title('Original gray image')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#-----------------------------Display LBP images----------------------------------#\n",
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True,\n",
    "                       figsize=(20, 20))\n",
    "\n",
    "ax[0].imshow(lbp_default, cmap=plt.cm.gray)\n",
    "ax[0].set_title('LBP-default-method')\n",
    "\n",
    "ax[1].imshow(lbp_var, cmap=plt.cm.gray)\n",
    "ax[1].set_title('LBP-var-method')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature description\n",
    "SIFT (Scale-Invariant Feature Transform) and SURF (Speeded-Up Robust Features) are good in what they do, but what if you have to pay a few dollars every year to use them in your applications? Yeah, they are patented!!! To solve that problem, OpenCV devs came up with a new \"FREE\" alternative to SIFT & SURF, and that is ORB (Oriented FAST and Rotated BRIEF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img_source = cv2.imread('./4.jpg')\n",
    "img_source_RGB = cv2.cvtColor(img_source,cv2.COLOR_BGR2RGB)\n",
    "img_gray = cv2.cvtColor(img_source,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Initiate ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# find the keypoints with ORB\n",
    "kp = orb.detect(img_gray,None)\n",
    "\n",
    "# compute the descriptors with ORB\n",
    "kp, des = orb.compute(img_gray, kp)\n",
    "\n",
    "# draw only keypoints location,not size and orientation\n",
    "img_orb = cv2.drawKeypoints(img_source_RGB, kp, None, color=(0,255,0), flags=0)\n",
    "\n",
    "#-----------------------------Display images----------------------------------#\n",
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True,\n",
    "                       figsize=(20, 20))\n",
    "\n",
    "ax[0].imshow(img_orb)\n",
    "ax[0].set_title('Feature discription')\n",
    "\n",
    "ax[1].imshow(img_source_RGB)\n",
    "ax[1].set_title('Original color image')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
